# ğŸ¡ California Housing Price Prediction (Random Forest)

This project builds a **Machine Learning web application** to predict **California house prices** using the **California Housing Dataset**.

The final deployed model uses a **Random Forest Regressor** and is served through a **Streamlit web interface**.

---

## ğŸ“Œ Project Overview

The project demonstrates:

- ğŸŒ² Random Forest Regression to predict house prices (in dollars)
- ğŸ“Š Model evaluation using RÂ² and MSE
- ğŸ–¥ï¸ Interactive Streamlit web application
- ğŸš€ Deployment-ready ML project

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                   # Streamlit application
â”œâ”€â”€ model.pkl                # Trained Random Forest model
â”œâ”€â”€ Prediction.ipynb         # Model training notebook
â”œâ”€â”€ README.md                # Project documentation
```

---

## ğŸ“Š Dataset

**California Housing Dataset**  
Source: `sklearn.datasets.fetch_california_housing`  
Based on 1990 California Census data.

---

### ğŸ”¹ Features Used

| Feature   | Description                                      |
|-----------|--------------------------------------------------|
| MedInc    | Median income (in tens of thousands of dollars) |
| HouseAge  | Median age of houses                            |
| AveRooms  | Average number of rooms per household           |
| AveBedrms | Average number of bedrooms per household        |

---

### ğŸ¯ Target Variable

| Variable | Description                      |
|----------|----------------------------------|
| PRICE    | Median house value in US dollars |

### Target Scaling

```python
df["PRICE"] = housing.target * 100000
```

---

## ğŸ§  Model Used

### ğŸŒ² Random Forest Regressor

### Why Random Forest?

- Handles non-linear relationships
- More robust than Linear Regression
- Reduces overfitting via ensemble learning
- Performs well on structured/tabular data

---

## âš™ï¸ Data Preprocessing

- Converted target variable to **dollars**
- Ensured **unit consistency** across:
  - Training
  - Testing
  - Prediction
  - Visualization

---

## ğŸ“ˆ Model Evaluation

### Evaluation Metrics

- **RÂ² Score**
- **Mean Squared Error (MSE)**

Random Forest improves prediction performance compared to simple linear models by capturing complex feature interactions.

---

## ğŸ–¥ï¸ Streamlit Web Application

### ğŸ”¹ Features

- User-friendly interface
- Median Income entered in **real dollars**
- Automatic conversion to dataset scale
- Real-time prediction output

### Example Scaling in App

```python
user_income = st.number_input("Median Income ($)", value=60000)
medinc = user_income / 10000
```

### Output

- ğŸ  Predicted house price (USD)

---

## â–¶ï¸ Run the Application

```bash
streamlit run app.py
```

---

## ğŸ› ï¸ Installation & Requirements

```bash
pip install numpy pandas scikit-learn streamlit
```

---

## âœ… Results & Insights

- Median Income is the most influential feature
- Random Forest provides strong predictive performance
- Model generalizes well with proper hyperparameter tuning

---

## ğŸš€ Future Improvements

- Add Latitude & Longitude features
- Add feature importance visualization in Streamlit
- SHAP explainability integration
- Try XGBoost or LightGBM
- Docker containerization for deployment

---

## ğŸ“œ License

This project is for educational and demonstration purposes.